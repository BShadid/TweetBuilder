Milestones for Twitter Recursive Nerual Network:

Quirks with Twitter's API v1.1 endpoint:

- Curling the API endpoint requires both a search query and an OAuth signature.
  Because of this, we won't be able to get all tweets, but we can search by a
  keyword in the tweet's text.
- It can only be curled 180 times per 15-minute window if we curl using
  user-authorization, and 450 times per 15-minute window if we curl using
  app-authorization.
- Classic_tweets only gives the first 140 characters of the tweet, which are
  not included in the character limit for the twitter website, so tweets might
  be truncated.


0. Find a way to curl twitter's API either by using a consumer key or a
documented workaround. (We may have to use twurl for this)

1. Retrieve JSON file from Twitter's API endpoint using python.

2. Parse this JSON file for the word information that we want to utilize.

3. Use a big data parsing method (something like a map-reduce method) to 
generate a list of words and their frequencies and discard unimportant ones.

4. Use GNU's default graphics library (graphics.py) to generate words by size
according to their frequencies (This size might increase logarithmically)

5. Develop an algorithm that maps these words in a non-overlapping word cloud.

6. Allow user interaction to affect the word cloud (e.g. when the user clicks a
word, it is placed in the center of the window)

7. Develop a method for calculating correlation between a master word and the
other words included in the JSON.

8. When a word is clicked, generate a map/tree that connects the selected word
to words that it is most commonly used with (trivial words have been removed at
this point)

9. Do this for each of the words in the list and implement recursion (i.e. The
clicking feature continues as long as the user keeps clicking words in the tree
or until the correlation of words is below the correlation threshold. 

10. Use either multiprocessing or another method to have this iteraction run in
near-interactive time. (Since we may end up using markov chains or a
covariance/correlation matrix for recursive tree generation, this process should
be mathematically "memoryless", and the program should only have a space
complexity of O(n)).

Steps 1-10 should be equally weighted at 4 points each. Step 0 is only a
prerequisite for running this script successfully.
